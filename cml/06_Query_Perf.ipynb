{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d1cebf-2750-4962-a0bb-850c7bf9509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure yo install requirements before running this\n",
    "#requirements.txt contains the sparkmeasure package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "521672b8-ad93-4692-979e-54270610f634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93b1f4d2-38e2-41c7-88ed-99f94ad6487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "717fc3c4-b2ea-46e5-83c8-5ce711a99f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/runtime-addons/spark320-18-hf3-c1r4x9d/opt/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/cdsw/.ivy2/cache\n",
      "The jars for the packages stored in: /home/cdsw/.ivy2/jars\n",
      "ch.cern.sparkmeasure#spark-measure_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-1a357843-f956-4921-8f1e-28dcbaff0bd6;1.0\n",
      "\tconfs: [default]\n",
      "\tfound ch.cern.sparkmeasure#spark-measure_2.12;0.23 in central\n",
      "\tfound com.fasterxml.jackson.module#jackson-module-scala_2.12;2.13.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.13.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.13.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.13.3 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.36 in central\n",
      "\tfound org.influxdb#influxdb-java;2.14 in central\n",
      "\tfound com.squareup.retrofit2#retrofit;2.4.0 in central\n",
      "\tfound com.squareup.retrofit2#converter-moshi;2.4.0 in central\n",
      "\tfound com.squareup.moshi#moshi;1.5.0 in central\n",
      "\tfound com.squareup.okio#okio;1.13.0 in central\n",
      "\tfound org.msgpack#msgpack-core;0.8.16 in central\n",
      "\tfound com.squareup.okhttp3#okhttp;3.11.0 in central\n",
      "\tfound com.squareup.okio#okio;1.14.0 in central\n",
      "\tfound com.squareup.okhttp3#logging-interceptor;3.11.0 in central\n",
      "\tfound org.apache.kafka#kafka-clients;3.2.1 in central\n",
      "\tfound com.github.luben#zstd-jni;1.5.2-1 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.8.4 in central\n",
      ":: resolution report :: resolve 967ms :: artifacts dl 119ms\n",
      "\t:: modules in use:\n",
      "\tch.cern.sparkmeasure#spark-measure_2.12;0.23 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.13.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.13.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.13.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.module#jackson-module-scala_2.12;2.13.3 from central in [default]\n",
      "\tcom.github.luben#zstd-jni;1.5.2-1 from central in [default]\n",
      "\tcom.squareup.moshi#moshi;1.5.0 from central in [default]\n",
      "\tcom.squareup.okhttp3#logging-interceptor;3.11.0 from central in [default]\n",
      "\tcom.squareup.okhttp3#okhttp;3.11.0 from central in [default]\n",
      "\tcom.squareup.okio#okio;1.14.0 from central in [default]\n",
      "\tcom.squareup.retrofit2#converter-moshi;2.4.0 from central in [default]\n",
      "\tcom.squareup.retrofit2#retrofit;2.4.0 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.8 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;3.2.1 from central in [default]\n",
      "\torg.influxdb#influxdb-java;2.14 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.msgpack#msgpack-core;0.8.16 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.36 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.8.4 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.squareup.okhttp3#okhttp;3.10.0 by [com.squareup.okhttp3#okhttp;3.11.0] in [default]\n",
      "\tcom.squareup.okio#okio;1.13.0 by [com.squareup.okio#okio;1.14.0] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   21  |   0   |   0   |   2   ||   19  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-1a357843-f956-4921-8f1e-28dcbaff0bd6\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 19 already retrieved (0kB/37ms)\n",
      "Setting spark.hadoop.yarn.resourcemanager.principal to pauldefusco\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"PythonSQL\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.s3guard.ddb.region\",\"us-east-2\")\\\n",
    "    .config(\"spark.yarn.access.hadoopFileSystems\",\"s3a://go01-demo\")\\\n",
    "    .config(\"spark.jars.packages\",\"ch.cern.sparkmeasure:spark-measure_2.12:0.23\")\\\n",
    "    .config(\"spark.dynamicAllocation.enabled\",\"false\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47a63545-1ec5-4c9d-aa37-fd580e694f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.dynamicAllocation.enabled', 'false'),\n",
       " ('spark.eventLog.enabled', 'true'),\n",
       " ('spark.hadoop.fs.s3a.s3guard.ddb.region', 'us-east-2'),\n",
       " ('spark.network.crypto.enabled', 'true'),\n",
       " ('spark.app.id', 'spark-application-1683253559571'),\n",
       " ('spark.app.initial.file.urls',\n",
       "  'spark://100.100.249.154:39123/files/com.thoughtworks.paranamer_paranamer-2.8.jar,spark://100.100.249.154:39123/files/ch.cern.sparkmeasure_spark-measure_2.12-0.23.jar,spark://100.100.249.154:39123/files/org.apache.kafka_kafka-clients-3.2.1.jar,spark://100.100.249.154:39123/files/com.squareup.moshi_moshi-1.5.0.jar,spark://100.100.249.154:39123/files/com.squareup.retrofit2_retrofit-2.4.0.jar,spark://100.100.249.154:39123/files/org.lz4_lz4-java-1.8.0.jar,spark://100.100.249.154:39123/files/com.squareup.okhttp3_okhttp-3.11.0.jar,spark://100.100.249.154:39123/files/com.fasterxml.jackson.module_jackson-module-scala_2.12-2.13.3.jar,spark://100.100.249.154:39123/files/com.github.luben_zstd-jni-1.5.2-1.jar,spark://100.100.249.154:39123/files/com.squareup.retrofit2_converter-moshi-2.4.0.jar,spark://100.100.249.154:39123/files/org.msgpack_msgpack-core-0.8.16.jar,spark://100.100.249.154:39123/files/com.squareup.okio_okio-1.14.0.jar,spark://100.100.249.154:39123/files/org.influxdb_influxdb-java-2.14.jar,spark://100.100.249.154:39123/files/com.fasterxml.jackson.core_jackson-core-2.13.3.jar,spark://100.100.249.154:39123/files/com.squareup.okhttp3_logging-interceptor-3.11.0.jar,spark://100.100.249.154:39123/files/org.xerial.snappy_snappy-java-1.1.8.4.jar,spark://100.100.249.154:39123/files/com.fasterxml.jackson.core_jackson-annotations-2.13.3.jar,spark://100.100.249.154:39123/files/org.slf4j_slf4j-api-1.7.36.jar,spark://100.100.249.154:39123/files/com.fasterxml.jackson.core_jackson-databind-2.13.3.jar'),\n",
       " ('spark.driver.memory', '1525m'),\n",
       " ('spark.kerberos.renewal.credentials', 'ccache'),\n",
       " ('spark.app.initial.jar.urls',\n",
       "  'spark://100.100.249.154:39123/jars/ch.cern.sparkmeasure_spark-measure_2.12-0.23.jar,spark://100.100.249.154:39123/jars/org.apache.kafka_kafka-clients-3.2.1.jar,spark://100.100.249.154:39123/jars/com.fasterxml.jackson.core_jackson-core-2.13.3.jar,spark://100.100.249.154:39123/jars/com.fasterxml.jackson.core_jackson-databind-2.13.3.jar,spark://100.100.249.154:39123/jars/com.squareup.moshi_moshi-1.5.0.jar,spark://100.100.249.154:39123/jars/org.influxdb_influxdb-java-2.14.jar,spark://100.100.249.154:39123/jars/org.lz4_lz4-java-1.8.0.jar,spark://100.100.249.154:39123/jars/com.squareup.okhttp3_logging-interceptor-3.11.0.jar,spark://100.100.249.154:39123/jars/com.squareup.okhttp3_okhttp-3.11.0.jar,spark://100.100.249.154:39123/jars/org.msgpack_msgpack-core-0.8.16.jar,spark://100.100.249.154:39123/jars/com.squareup.okio_okio-1.14.0.jar,spark://100.100.249.154:39123/jars/com.fasterxml.jackson.core_jackson-annotations-2.13.3.jar,spark://100.100.249.154:39123/jars/com.thoughtworks.paranamer_paranamer-2.8.jar,spark://100.100.249.154:39123/jars/com.squareup.retrofit2_retrofit-2.4.0.jar,spark://100.100.249.154:39123/jars/com.squareup.retrofit2_converter-moshi-2.4.0.jar,spark://100.100.249.154:39123/jars/com.fasterxml.jackson.module_jackson-module-scala_2.12-2.13.3.jar,spark://100.100.249.154:39123/jars/com.github.luben_zstd-jni-1.5.2-1.jar,spark://100.100.249.154:39123/jars/org.slf4j_slf4j-api-1.7.36.jar,spark://100.100.249.154:39123/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar'),\n",
       " ('spark.dynamicAllocation.maxExecutors', '49'),\n",
       " ('spark.eventLog.dir', 'file:///sparkeventlogs'),\n",
       " ('spark.hadoop.yarn.resourcemanager.principal', 'pauldefusco'),\n",
       " ('spark.app.startTime', '1683253557606'),\n",
       " ('spark.kubernetes.driver.annotation.cluster-autoscaler.kubernetes.io/safe-to-evict',\n",
       "  'false'),\n",
       " ('spark.ui.port', '20049'),\n",
       " ('spark.repl.local.jars',\n",
       "  'file:///home/cdsw/.ivy2/jars/ch.cern.sparkmeasure_spark-measure_2.12-0.23.jar,file:///home/cdsw/.ivy2/jars/com.fasterxml.jackson.module_jackson-module-scala_2.12-2.13.3.jar,file:///home/cdsw/.ivy2/jars/org.slf4j_slf4j-api-1.7.36.jar,file:///home/cdsw/.ivy2/jars/org.influxdb_influxdb-java-2.14.jar,file:///home/cdsw/.ivy2/jars/org.apache.kafka_kafka-clients-3.2.1.jar,file:///home/cdsw/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.13.3.jar,file:///home/cdsw/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.13.3.jar,file:///home/cdsw/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.13.3.jar,file:///home/cdsw/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar,file:///home/cdsw/.ivy2/jars/com.squareup.retrofit2_retrofit-2.4.0.jar,file:///home/cdsw/.ivy2/jars/com.squareup.retrofit2_converter-moshi-2.4.0.jar,file:///home/cdsw/.ivy2/jars/org.msgpack_msgpack-core-0.8.16.jar,file:///home/cdsw/.ivy2/jars/com.squareup.okhttp3_okhttp-3.11.0.jar,file:///home/cdsw/.ivy2/jars/com.squareup.okhttp3_logging-interceptor-3.11.0.jar,file:///home/cdsw/.ivy2/jars/com.squareup.moshi_moshi-1.5.0.jar,file:///home/cdsw/.ivy2/jars/com.squareup.okio_okio-1.14.0.jar,file:///home/cdsw/.ivy2/jars/com.github.luben_zstd-jni-1.5.2-1.jar,file:///home/cdsw/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar,file:///home/cdsw/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar'),\n",
       " ('spark.kubernetes.executor.annotation.cluster-autoscaler.kubernetes.io/safe-to-evict',\n",
       "  'false'),\n",
       " ('spark.io.encryption.enabled', 'true'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.yarn.access.hadoopFileSystems', 's3a://go01-demo'),\n",
       " ('spark.master', 'k8s://https://172.20.0.1:443'),\n",
       " ('spark.kubernetes.executor.podTemplateFile', '/tmp/spark-executor.json'),\n",
       " ('spark.kubernetes.executor.podNamePrefix', 'cdsw-n7x9abcll1i6tdz3'),\n",
       " ('spark.kubernetes.container.image',\n",
       "  'docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.7-standard:2022.11.1-b2'),\n",
       " ('spark.dynamicAllocation.shuffleTracking.enabled', 'true'),\n",
       " ('spark.driver.bindAddress', '100.100.249.154'),\n",
       " ('spark.submit.pyFiles',\n",
       "  '/home/cdsw/.ivy2/jars/ch.cern.sparkmeasure_spark-measure_2.12-0.23.jar,/home/cdsw/.ivy2/jars/com.fasterxml.jackson.module_jackson-module-scala_2.12-2.13.3.jar,/home/cdsw/.ivy2/jars/org.slf4j_slf4j-api-1.7.36.jar,/home/cdsw/.ivy2/jars/org.influxdb_influxdb-java-2.14.jar,/home/cdsw/.ivy2/jars/org.apache.kafka_kafka-clients-3.2.1.jar,/home/cdsw/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.13.3.jar,/home/cdsw/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.13.3.jar,/home/cdsw/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.13.3.jar,/home/cdsw/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar,/home/cdsw/.ivy2/jars/com.squareup.retrofit2_retrofit-2.4.0.jar,/home/cdsw/.ivy2/jars/com.squareup.retrofit2_converter-moshi-2.4.0.jar,/home/cdsw/.ivy2/jars/org.msgpack_msgpack-core-0.8.16.jar,/home/cdsw/.ivy2/jars/com.squareup.okhttp3_okhttp-3.11.0.jar,/home/cdsw/.ivy2/jars/com.squareup.okhttp3_logging-interceptor-3.11.0.jar,/home/cdsw/.ivy2/jars/com.squareup.moshi_moshi-1.5.0.jar,/home/cdsw/.ivy2/jars/com.squareup.okio_okio-1.14.0.jar,/home/cdsw/.ivy2/jars/com.github.luben_zstd-jni-1.5.2-1.jar,/home/cdsw/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar,/home/cdsw/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar'),\n",
       " ('spark.files',\n",
       "  'file:///home/cdsw/.ivy2/jars/ch.cern.sparkmeasure_spark-measure_2.12-0.23.jar,file:///home/cdsw/.ivy2/jars/com.fasterxml.jackson.module_jackson-module-scala_2.12-2.13.3.jar,file:///home/cdsw/.ivy2/jars/org.slf4j_slf4j-api-1.7.36.jar,file:///home/cdsw/.ivy2/jars/org.influxdb_influxdb-java-2.14.jar,file:///home/cdsw/.ivy2/jars/org.apache.kafka_kafka-clients-3.2.1.jar,file:///home/cdsw/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.13.3.jar,file:///home/cdsw/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.13.3.jar,file:///home/cdsw/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.13.3.jar,file:///home/cdsw/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar,file:///home/cdsw/.ivy2/jars/com.squareup.retrofit2_retrofit-2.4.0.jar,file:///home/cdsw/.ivy2/jars/com.squareup.retrofit2_converter-moshi-2.4.0.jar,file:///home/cdsw/.ivy2/jars/org.msgpack_msgpack-core-0.8.16.jar,file:///home/cdsw/.ivy2/jars/com.squareup.okhttp3_okhttp-3.11.0.jar,file:///home/cdsw/.ivy2/jars/com.squareup.okhttp3_logging-interceptor-3.11.0.jar,file:///home/cdsw/.ivy2/jars/com.squareup.moshi_moshi-1.5.0.jar,file:///home/cdsw/.ivy2/jars/com.squareup.okio_okio-1.14.0.jar,file:///home/cdsw/.ivy2/jars/com.github.luben_zstd-jni-1.5.2-1.jar,file:///home/cdsw/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar,file:///home/cdsw/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar'),\n",
       " ('spark.kubernetes.namespace', 'mlx-user-16'),\n",
       " ('spark.kubernetes.driver.pod.name', 'n7x9abcll1i6tdz3'),\n",
       " ('spark.driver.host', '100.100.249.154'),\n",
       " ('spark.jars.packages', 'ch.cern.sparkmeasure:spark-measure_2.12:0.23'),\n",
       " ('spark.kubernetes.executor.config.dir', '/var/spark/conf'),\n",
       " ('spark.sql.warehouse.dir',\n",
       "  's3a://go01-demo/warehouse/tablespace/external/hive'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.jars',\n",
       "  'file:///home/cdsw/.ivy2/jars/ch.cern.sparkmeasure_spark-measure_2.12-0.23.jar,file:///home/cdsw/.ivy2/jars/com.fasterxml.jackson.module_jackson-module-scala_2.12-2.13.3.jar,file:///home/cdsw/.ivy2/jars/org.slf4j_slf4j-api-1.7.36.jar,file:///home/cdsw/.ivy2/jars/org.influxdb_influxdb-java-2.14.jar,file:///home/cdsw/.ivy2/jars/org.apache.kafka_kafka-clients-3.2.1.jar,file:///home/cdsw/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.13.3.jar,file:///home/cdsw/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.13.3.jar,file:///home/cdsw/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.13.3.jar,file:///home/cdsw/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar,file:///home/cdsw/.ivy2/jars/com.squareup.retrofit2_retrofit-2.4.0.jar,file:///home/cdsw/.ivy2/jars/com.squareup.retrofit2_converter-moshi-2.4.0.jar,file:///home/cdsw/.ivy2/jars/org.msgpack_msgpack-core-0.8.16.jar,file:///home/cdsw/.ivy2/jars/com.squareup.okhttp3_okhttp-3.11.0.jar,file:///home/cdsw/.ivy2/jars/com.squareup.okhttp3_logging-interceptor-3.11.0.jar,file:///home/cdsw/.ivy2/jars/com.squareup.moshi_moshi-1.5.0.jar,file:///home/cdsw/.ivy2/jars/com.squareup.okio_okio-1.14.0.jar,file:///home/cdsw/.ivy2/jars/com.github.luben_zstd-jni-1.5.2-1.jar,file:///home/cdsw/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar,file:///home/cdsw/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar'),\n",
       " ('spark.app.name', 'PythonSQL'),\n",
       " ('spark.yarn.rmProxy.enabled', 'false'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('spark.driver.port', '39123'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.ui.allowFramingFrom',\n",
       "  'https://ml-4c5feac0-3ec.go01-dem.ylcu-atmi.cloudera.site'),\n",
       " ('spark.ui.proxyRedirectUri',\n",
       "  'https://spark-n7x9abcll1i6tdz3.ml-4c5feac0-3ec.go01-dem.ylcu-atmi.cloudera.site'),\n",
       " ('spark.deploy.mode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.authenticate', 'true')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f1d9ba6-75ae-4f22-9662-3200753627b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://spark-n7x9abcll1i6tdz3.ml-4c5feac0-3ec.go01-dem.ylcu-atmi.cloudera.site\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"https://spark-\"+os.environ[\"CDSW_ENGINE_ID\"]+\".\"+os.environ[\"CDSW_DOMAIN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8317e009-0a45-41ef-8618-c8c5fc518978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      "\n",
      "root\n",
      " |-- person_name: string (nullable = false)\n",
      " |-- person_age: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import Row, StructField, StructType, StringType, IntegerType\n",
    "# A list of Rows. Infer schema from the first row, create a DataFrame and print the schema\n",
    "rows = [Row(name=\"John\", age=19), Row(name=\"Smith\", age=23), Row(name=\"Sarah\", age=18)]\n",
    "some_df = spark.createDataFrame(rows)\n",
    "some_df.printSchema()\n",
    "\n",
    "# A list of tuples\n",
    "tuples = [(\"John\", 19), (\"Smith\", 23), (\"Sarah\", 18)]\n",
    "\n",
    "# Schema with two fields - person_name and person_age\n",
    "schema = StructType([StructField(\"person_name\", StringType(), False),\n",
    "                    StructField(\"person_age\", IntegerType(), False)])\n",
    "\n",
    "# Create a DataFrame by applying the schema to the RDD and print the schema\n",
    "another_df = spark.createDataFrame(tuples, schema)\n",
    "another_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "963f43eb-81a3-48b6-b7f3-a92f86be49af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://spark-n7x9abcll1i6tdz3.ml-4c5feac0-3ec.go01-dem.ylcu-atmi.cloudera.site\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"https://spark-\"+os.environ[\"CDSW_ENGINE_ID\"]+\".\"+os.environ[\"CDSW_DOMAIN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d798f34-94a7-49a5-b406-9fc4bc9b6b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.conf.get('spark.executor.cores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "927a4fe2-b5db-43e1-892b-229ec9906775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hive Session ID = 300bf600-8e44-4c87-80f3-b47fb3bb0ceb\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "another_df.write.mode(\"overwrite\").partitionBy('person_age').saveAsTable(\"cmltable\", format=\"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b994099a-ccea-4643-ad50-a335aca77d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize sparkMeasure\n",
    "# Load the Python API for sparkmeasure package\n",
    "# and attach the sparkMeasure Listener for stagemetrics to the active Spark session\n",
    "\n",
    "from sparkmeasure import StageMetrics\n",
    "stagemetrics = StageMetrics(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7f214ce-dccb-409b-a739-38840b1f75ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       3|\n",
      "+--------+\n",
      "\n",
      "\n",
      "Scheduling mode = FIFO\n",
      "Spark Context default degree of parallelism = 2\n",
      "\n",
      "Aggregated Spark stage metrics:\n",
      "numStages => 2\n",
      "numTasks => 3\n",
      "elapsedTime => 904 (0.9 s)\n",
      "stageDuration => 836 (0.8 s)\n",
      "executorRunTime => 1013 (1 s)\n",
      "executorCpuTime => 549 (0.5 s)\n",
      "executorDeserializeTime => 257 (0.3 s)\n",
      "executorDeserializeCpuTime => 233 (0.2 s)\n",
      "resultSerializationTime => 0 (0 ms)\n",
      "jvmGCTime => 28 (28 ms)\n",
      "shuffleFetchWaitTime => 0 (0 ms)\n",
      "shuffleWriteTime => 15 (15 ms)\n",
      "resultSize => 4286 (4.2 KB)\n",
      "diskBytesSpilled => 0 (0 Bytes)\n",
      "memoryBytesSpilled => 0 (0 Bytes)\n",
      "peakExecutionMemory => 0\n",
      "recordsRead => 3\n",
      "bytesRead => 2584 (2.5 KB)\n",
      "recordsWritten => 0\n",
      "bytesWritten => 0 (0 Bytes)\n",
      "shuffleRecordsRead => 2\n",
      "shuffleTotalBlocksFetched => 2\n",
      "shuffleLocalBlocksFetched => 1\n",
      "shuffleRemoteBlocksFetched => 1\n",
      "shuffleTotalBytesRead => 150 (150 Bytes)\n",
      "shuffleLocalBytesRead => 75 (75 Bytes)\n",
      "shuffleRemoteBytesRead => 75 (75 Bytes)\n",
      "shuffleRemoteBytesReadToDisk => 0 (0 Bytes)\n",
      "shuffleBytesWritten => 150 (150 Bytes)\n",
      "shuffleRecordsWritten => 2\n",
      "\n",
      "Stages and their duration:\n",
      "Stage 1 duration => 562 (0.6 s)\n",
      "Stage 3 duration => 274 (0.3 s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# The easiest way to start using sparkMesure is with the \"runandmeasure\" method\n",
    "# This will execute your Spark action, return the results, and collect and aggregate execution metrics\n",
    "\n",
    "stagemetrics.runandmeasure(globals(), \"\"\"\n",
    "spark.sql(\"select count(*) from cmltable\").show()\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfbdb82e-be1b-4e63-87c0-22e47b5e90d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scheduling mode = FIFO\n",
      "Spark Context default degree of parallelism = 2\n",
      "\n",
      "Aggregated Spark stage metrics:\n",
      "numStages => 0\n",
      "numTasks => 0\n",
      "elapsedTime => -9223372036854775807 (-9223372036854775807 ms)\n",
      "stageDuration => 0 (0 ms)\n",
      "executorRunTime => 0 (0 ms)\n",
      "executorCpuTime => 0 (0 ms)\n",
      "executorDeserializeTime => 0 (0 ms)\n",
      "executorDeserializeCpuTime => 0 (0 ms)\n",
      "resultSerializationTime => 0 (0 ms)\n",
      "jvmGCTime => 0 (0 ms)\n",
      "shuffleFetchWaitTime => 0 (0 ms)\n",
      "shuffleWriteTime => 0 (0 ms)\n",
      "resultSize => 0 (0 Bytes)\n",
      "diskBytesSpilled => 0 (0 Bytes)\n",
      "memoryBytesSpilled => 0 (0 Bytes)\n",
      "peakExecutionMemory => 0\n",
      "recordsRead => 0\n",
      "bytesRead => 0 (0 Bytes)\n",
      "recordsWritten => 0\n",
      "bytesWritten => 0 (0 Bytes)\n",
      "shuffleRecordsRead => 0\n",
      "shuffleTotalBlocksFetched => 0\n",
      "shuffleLocalBlocksFetched => 0\n",
      "shuffleRemoteBlocksFetched => 0\n",
      "shuffleTotalBytesRead => 0 (0 Bytes)\n",
      "shuffleLocalBytesRead => 0 (0 Bytes)\n",
      "shuffleRemoteBytesRead => 0 (0 Bytes)\n",
      "shuffleRemoteBytesReadToDisk => 0 (0 Bytes)\n",
      "shuffleBytesWritten => 0 (0 Bytes)\n",
      "shuffleRecordsWritten => 0\n",
      "\n",
      "Stages and their duration:\n"
     ]
    }
   ],
   "source": [
    "# An equivalent API for collecting execution metrics is to explicitly wrap your Spark workload\n",
    "# into stagemetrics instrumentation, as in this example\n",
    "\n",
    "stagemetrics.begin()\n",
    "\n",
    "df = spark.sql(\"select * from cmltable\")\n",
    "stagemetrics.end()\n",
    "\n",
    "# Print a summary report\n",
    "stagemetrics.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "241a49c1-c7d1-4ba7-b68b-7533b010bbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scheduling mode = FIFO\n",
      "Spark Context default degree of parallelism = 2\n",
      "\n",
      "Aggregated Spark stage metrics:\n",
      "numStages => 1\n",
      "numTasks => 2\n",
      "elapsedTime => 380 (0.4 s)\n",
      "stageDuration => 380 (0.4 s)\n",
      "executorRunTime => 553 (0.6 s)\n",
      "executorCpuTime => 159 (0.2 s)\n",
      "executorDeserializeTime => 102 (0.1 s)\n",
      "executorDeserializeCpuTime => 92 (92 ms)\n",
      "resultSerializationTime => 0 (0 ms)\n",
      "jvmGCTime => 0 (0 ms)\n",
      "shuffleFetchWaitTime => 0 (0 ms)\n",
      "shuffleWriteTime => 0 (0 ms)\n",
      "resultSize => 3434 (3.4 KB)\n",
      "diskBytesSpilled => 0 (0 Bytes)\n",
      "memoryBytesSpilled => 0 (0 Bytes)\n",
      "peakExecutionMemory => 0\n",
      "recordsRead => 3\n",
      "bytesRead => 4038 (3.9 KB)\n",
      "recordsWritten => 0\n",
      "bytesWritten => 0 (0 Bytes)\n",
      "shuffleRecordsRead => 0\n",
      "shuffleTotalBlocksFetched => 0\n",
      "shuffleLocalBlocksFetched => 0\n",
      "shuffleRemoteBlocksFetched => 0\n",
      "shuffleTotalBytesRead => 0 (0 Bytes)\n",
      "shuffleLocalBytesRead => 0 (0 Bytes)\n",
      "shuffleRemoteBytesRead => 0 (0 Bytes)\n",
      "shuffleRemoteBytesReadToDisk => 0 (0 Bytes)\n",
      "shuffleBytesWritten => 0 (0 Bytes)\n",
      "shuffleRecordsWritten => 0\n",
      "\n",
      "Stages and their duration:\n",
      "Stage 4 duration => 380 (0.4 s)\n"
     ]
    }
   ],
   "source": [
    "stagemetrics.begin()\n",
    "\n",
    "#new_df = df.coalesce(1)\n",
    "df.collect()\n",
    "\n",
    "stagemetrics.end()\n",
    "\n",
    "# Print a summary report\n",
    "stagemetrics.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed6a2170-994a-4d5f-ab10-92140f3b3192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scheduling mode = FIFO\n",
      "Spark Context default degree of parallelism = 2\n",
      "\n",
      "Aggregated Spark stage metrics:\n",
      "numStages => 1\n",
      "numTasks => 1\n",
      "elapsedTime => 424 (0.4 s)\n",
      "stageDuration => 424 (0.4 s)\n",
      "executorRunTime => 389 (0.4 s)\n",
      "executorCpuTime => 76 (76 ms)\n",
      "executorDeserializeTime => 19 (19 ms)\n",
      "executorDeserializeCpuTime => 13 (13 ms)\n",
      "resultSerializationTime => 0 (0 ms)\n",
      "jvmGCTime => 0 (0 ms)\n",
      "shuffleFetchWaitTime => 0 (0 ms)\n",
      "shuffleWriteTime => 0 (0 ms)\n",
      "resultSize => 1740 (1740 Bytes)\n",
      "diskBytesSpilled => 0 (0 Bytes)\n",
      "memoryBytesSpilled => 0 (0 Bytes)\n",
      "peakExecutionMemory => 0\n",
      "recordsRead => 3\n",
      "bytesRead => 4038 (3.9 KB)\n",
      "recordsWritten => 0\n",
      "bytesWritten => 0 (0 Bytes)\n",
      "shuffleRecordsRead => 0\n",
      "shuffleTotalBlocksFetched => 0\n",
      "shuffleLocalBlocksFetched => 0\n",
      "shuffleRemoteBlocksFetched => 0\n",
      "shuffleTotalBytesRead => 0 (0 Bytes)\n",
      "shuffleLocalBytesRead => 0 (0 Bytes)\n",
      "shuffleRemoteBytesRead => 0 (0 Bytes)\n",
      "shuffleRemoteBytesReadToDisk => 0 (0 Bytes)\n",
      "shuffleBytesWritten => 0 (0 Bytes)\n",
      "shuffleRecordsWritten => 0\n",
      "\n",
      "Stages and their duration:\n",
      "Stage 5 duration => 424 (0.4 s)\n"
     ]
    }
   ],
   "source": [
    "stagemetrics.begin()\n",
    "\n",
    "df = df.coalesce(1)\n",
    "df.collect()\n",
    "\n",
    "stagemetrics.end()\n",
    "\n",
    "# Print a summary report\n",
    "stagemetrics.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2ef396-6204-480e-9aef-3891e6bf91bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c86883-403f-404f-b863-053a72fffe49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4e1e89-3dc6-49aa-8ebf-68a55d2662fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47d1ad6-f15c-41fd-99bb-d737e9b5f00f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d35df96-892d-4cc9-85cd-ab60da9b06af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c27449-c078-4851-9365-b37d7556377b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f3b4f3-ee80-4e9e-ae67-7fe08c2bd5be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a08b66-0dce-4120-b187-308f5368b30a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcad074-b4d8-4778-b9c9-f596f2d8c6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b777456-3579-487c-aa3a-164e30f445e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc049d82-a705-4b27-b36a-e4351704e245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e21ce3-b0b1-4bd0-9f9b-0377efc30566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1231217-8c6c-46f3-954c-16ac2f6d16b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432bb7a1-124c-49fb-bd6e-8543cefd2f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954ecc61-0eba-43c0-b26c-313dfa2d927b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ea85826-6575-474f-bacc-d3e9f38b9654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(spark.conf.get('spark.sql.shuffle.partitions'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "757dfc54-8e4b-4533-862e-3153f8e8f5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://spark-rc6ogaxo81567r3w.ml-4c5feac0-3ec.go01-dem.ylcu-atmi.cloudera.site\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"https://spark-\"+os.environ[\"CDSW_ENGINE_ID\"]+\".\"+os.environ[\"CDSW_DOMAIN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07ffb347-c66f-47da-b54e-370dd7a14de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is for Jupyter notebooks\n",
    "# Define cell and line magic to wrap sparkmeasure instrumentation\n",
    "# See example in the next cell\n",
    "\n",
    "from IPython.core.magic import (register_line_magic, register_cell_magic, register_line_cell_magic)\n",
    "\n",
    "@register_line_cell_magic\n",
    "def sparkmeasure(line, cell=None):\n",
    "    \"run and measure spark workload. Use: %sparkmeasure or %%sparkmeasure\"\n",
    "    val = cell if cell is not None else line\n",
    "    stagemetrics.begin()\n",
    "    eval(val)\n",
    "    stagemetrics.end()\n",
    "    stagemetrics.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a13e7e7b-0e84-4d04-a273-cfda3a9263ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  count(1)|\n",
      "+----------+\n",
      "|1000000000|\n",
      "+----------+\n",
      "\n",
      "\n",
      "Scheduling mode = FIFO\n",
      "Spark Context default degree of parallelism = 2\n",
      "\n",
      "Aggregated Spark task metrics:\n",
      "numTasks => 5\n",
      "successful tasks => 5\n",
      "speculative tasks => 0\n",
      "taskDuration => 872 (0.9 s)\n",
      "schedulerDelayTime => 35 (35 ms)\n",
      "executorRunTime => 778 (0.8 s)\n",
      "executorCpuTime => 766 (0.8 s)\n",
      "executorDeserializeTime => 59 (59 ms)\n",
      "executorDeserializeCpuTime => 31 (31 ms)\n",
      "resultSerializationTime => 0 (0 ms)\n",
      "jvmGCTime => 0 (0 ms)\n",
      "shuffleFetchWaitTime => 0 (0 ms)\n",
      "shuffleWriteTime => 0 (0 ms)\n",
      "gettingResultTime => 0 (0 ms)\n",
      "resultSize => 2659 (2.6 KB)\n",
      "diskBytesSpilled => 0 (0 Bytes)\n",
      "memoryBytesSpilled => 0 (0 Bytes)\n",
      "peakExecutionMemory => 0\n",
      "recordsRead => 2000\n",
      "bytesRead => 0 (0 Bytes)\n",
      "recordsWritten => 0\n",
      "bytesWritten => 0 (0 Bytes)\n",
      "shuffleRecordsRead => 2\n",
      "shuffleTotalBlocksFetched => 2\n",
      "shuffleLocalBlocksFetched => 1\n",
      "shuffleRemoteBlocksFetched => 1\n",
      "shuffleTotalBytesRead => 148 (148 Bytes)\n",
      "shuffleLocalBytesRead => 74 (74 Bytes)\n",
      "shuffleRemoteBytesRead => 74 (74 Bytes)\n",
      "shuffleRemoteBytesReadToDisk => 0 (0 Bytes)\n",
      "shuffleBytesWritten => 148 (148 Bytes)\n",
      "shuffleRecordsWritten => 2\n"
     ]
    }
   ],
   "source": [
    "from sparkmeasure import TaskMetrics\n",
    "taskmetrics = TaskMetrics(spark)\n",
    "\n",
    "taskmetrics.begin()\n",
    "spark.sql(\"select count(*) from range(1000) cross join range(1000) cross join range(1000)\").show()\n",
    "taskmetrics.end()\n",
    "\n",
    "taskmetrics.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbb0846-bac4-4785-9cc1-69da02e55918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
