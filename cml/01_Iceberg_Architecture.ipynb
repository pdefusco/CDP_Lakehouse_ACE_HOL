{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0942afe9-7629-4b3e-b747-b795a6454a2b",
   "metadata": {},
   "source": [
    "## Introduction to Iceberg Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd15c6f-e31d-440c-bc48-966385b7c5ec",
   "metadata": {},
   "source": [
    "#### Launching a Spark Session with Iceberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f139b6a-eed6-4848-9e82-593aabad58b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting spark.hadoop.yarn.resourcemanager.principal to pauldefusco\n",
      "Hive Session ID = ba8f8f3e-1900-41c3-b249-edf7f74b0743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           namespace|\n",
      "+--------------------+\n",
      "|         01_car_data|\n",
      "|           01_car_dw|\n",
      "|      adash_car_data|\n",
      "|             airline|\n",
      "|          airline_dw|\n",
      "|            airlines|\n",
      "|        airlines_csv|\n",
      "|       airlines_csv1|\n",
      "|   airlines_csv_vish|\n",
      "|    airlines_iceberg|\n",
      "|   airlines_iceberg1|\n",
      "|airlines_iceberg_...|\n",
      "|      airlines_mjain|\n",
      "|          airquality|\n",
      "|          atlas_demo|\n",
      "|            bankdemo|\n",
      "|              bhagan|\n",
      "|             cdedemo|\n",
      "|        cdp_overview|\n",
      "|        cgsifacebook|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cml.data_v1 as cmldata\n",
    "\n",
    "CONNECTION_NAME = \"go01-aw-dl\"\n",
    "conn = cmldata.get_connection(CONNECTION_NAME)\n",
    "spark = conn.get_spark_session()\n",
    "\n",
    "# Sample usage to run query through spark\n",
    "EXAMPLE_SQL_QUERY = \"show databases\"\n",
    "spark.sql(EXAMPLE_SQL_QUERY).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3bbf1bf-a0a1-4864-8c98-88dfb994060a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.eventLog.enabled', 'true'),\n",
       " ('spark.app.startTime', '1682526095537'),\n",
       " ('spark.repl.local.jars',\n",
       "  'file:///runtime-addons/spark320-17-hf1-6xa3lk/opt/spark/optional-lib/iceberg-spark-runtime-3.2_2.12-0.14.1.1.17.7215.0-31.jar'),\n",
       " ('spark.driver.bindAddress', '100.100.178.94'),\n",
       " ('spark.network.crypto.enabled', 'true'),\n",
       " ('spark.sql.hive.hwc.execution.mode', 'spark'),\n",
       " ('spark.kerberos.renewal.credentials', 'ccache'),\n",
       " ('spark.sql.catalog.spark_catalog',\n",
       "  'org.apache.iceberg.spark.SparkSessionCatalog'),\n",
       " ('spark.dynamicAllocation.maxExecutors', '49'),\n",
       " ('spark.eventLog.dir', 'file:///sparkeventlogs'),\n",
       " ('spark.hadoop.yarn.resourcemanager.principal', 'pauldefusco'),\n",
       " ('spark.kubernetes.driver.annotation.cluster-autoscaler.kubernetes.io/safe-to-evict',\n",
       "  'false'),\n",
       " ('spark.ui.port', '20049'),\n",
       " ('spark.yarn.access.hadoopFileSystems',\n",
       "  's3a://go01-demo/warehouse/tablespace/external/hive'),\n",
       " ('spark.sql.extensions',\n",
       "  'com.qubole.spark.hiveacid.HiveAcidAutoConvertExtension,org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions'),\n",
       " ('spark.kubernetes.executor.annotation.cluster-autoscaler.kubernetes.io/safe-to-evict',\n",
       "  'false'),\n",
       " ('spark.driver.memory', '3051m'),\n",
       " ('spark.app.id', 'spark-application-1682526097424'),\n",
       " ('spark.io.encryption.enabled', 'true'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.master', 'k8s://https://172.20.0.1:443'),\n",
       " ('spark.kubernetes.executor.podTemplateFile', '/tmp/spark-executor.json'),\n",
       " ('spark.jars', '/opt/spark/optional-lib/iceberg-spark-runtime.jar'),\n",
       " ('spark.dynamicAllocation.shuffleTracking.enabled', 'true'),\n",
       " ('spark.kubernetes.container.image',\n",
       "  'docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.7-standard:2022.11.1-b2'),\n",
       " ('spark.kubernetes.driver.pod.name', '33itijpr8nh6i1ia'),\n",
       " ('spark.kubernetes.namespace', 'mlx-user-16'),\n",
       " ('spark.driver.port', '42215'),\n",
       " ('spark.kubernetes.executor.config.dir', '/var/spark/conf'),\n",
       " ('spark.sql.warehouse.dir',\n",
       "  's3a://go01-demo/warehouse/tablespace/external/hive'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.kubernetes.executor.podNamePrefix', 'cdsw-33itijpr8nh6i1ia'),\n",
       " ('spark.yarn.rmProxy.enabled', 'false'),\n",
       " ('spark.app.initial.jar.urls',\n",
       "  'spark://100.100.178.94:42215/jars/iceberg-spark-runtime-3.2_2.12-0.14.1.1.17.7215.0-31.jar'),\n",
       " ('spark.driver.host', '100.100.178.94'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.kryo.registrator',\n",
       "  'com.qubole.spark.hiveacid.util.HiveAcidKyroRegistrator'),\n",
       " ('spark.ui.allowFramingFrom',\n",
       "  'https://ml-4c5feac0-3ec.go01-dem.ylcu-atmi.cloudera.site'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.dynamicAllocation.enabled', 'true'),\n",
       " ('spark.deploy.mode', 'client'),\n",
       " ('spark.ui.proxyRedirectUri',\n",
       "  'https://spark-33itijpr8nh6i1ia.ml-4c5feac0-3ec.go01-dem.ylcu-atmi.cloudera.site'),\n",
       " ('spark.app.name', 'None'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.sql.catalog.spark_catalog.type', 'hive'),\n",
       " ('spark.authenticate', 'true')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa007770-01e4-4c2e-a784-6955c448c952",
   "metadata": {},
   "source": [
    "### Iceberg Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad5615b-c7e6-4528-bd48-db0841d38c39",
   "metadata": {},
   "source": [
    "![alt text](../img/iceberg-metadata.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c3c93c-4065-422b-9697-609ae50687c7",
   "metadata": {},
   "source": [
    "#### Iceberg Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30001dd5-c3ef-4223-84ca-e63552c4f879",
   "metadata": {},
   "source": [
    "Iceberg comes with catalogs that enable SQL commands to manage tables and load them by name. Catalogs are configured using properties under spark.sql.catalog.(catalog_name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3819a08-8e00-4184-bdc6-79b3d8507d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+\n",
      "|      catalog|namespace|\n",
      "+-------------+---------+\n",
      "|spark_catalog|  default|\n",
      "+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show catalog and database\n",
    "spark.sql(\"SHOW CURRENT NAMESPACE\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1119faa-93a7-4ebe-85b1-3ec87eb54b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new database\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS spark_catalog.lakehouse_catalog\")\n",
    "spark.sql(\"USE spark_catalog.lakehouse_catalog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "834ca50c-9c2f-43ac-9ec0-9cf28e8507d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+\n",
      "|      catalog|        namespace|\n",
      "+-------------+-----------------+\n",
      "|spark_catalog|lakehouse_catalog|\n",
      "+-------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show catalog and database\n",
    "spark.sql(\"SHOW CURRENT NAMESPACE\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6cecda-848a-4cbe-b7a8-d73096cab11f",
   "metadata": {},
   "source": [
    "#### Create an Iceberg Table with Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c5daa62-cde3-440a-ad91-0c6f9b41ef3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS customers_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b19e0de9-29c4-43dd-ae5c-c2bd69558032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE TABLE IF NOT EXISTS customers_table (id BIGINT, state STRING, country STRING, dob TIMESTAMP) USING iceberg PARTITIONED BY ( hours(dob))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eea95e7-e221-4997-9071-208cbc9f9fc5",
   "metadata": {},
   "source": [
    "#### Verify that a Metadata JSON file has been created under the Metadata directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2668955d-14e9-43c9-a359-61cd9ae5bff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = \"s3a://go01-demo/warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfa6cae7-8598-4088-8de8-751341c257b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata/00000-e19a6100-50ef-4556-a1ad-d13018d6286e.metadata.json\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket(\"go01-demo\")\n",
    "\n",
    "for object_summary in my_bucket.objects.filter(Prefix=\"warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata\"):\n",
    "    print(object_summary.key)\n",
    "    metadata_file = object_summary.key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e03d542a-f982-4b9a-bc19-84a26d504cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current-schema-id</th>\n",
       "      <th>current-snapshot-id</th>\n",
       "      <th>default-sort-order-id</th>\n",
       "      <th>default-spec-id</th>\n",
       "      <th>format-version</th>\n",
       "      <th>last-column-id</th>\n",
       "      <th>last-partition-id</th>\n",
       "      <th>last-updated-ms</th>\n",
       "      <th>location</th>\n",
       "      <th>metadata-log</th>\n",
       "      <th>partition-spec</th>\n",
       "      <th>partition-specs</th>\n",
       "      <th>properties</th>\n",
       "      <th>schema</th>\n",
       "      <th>schemas</th>\n",
       "      <th>snapshot-log</th>\n",
       "      <th>snapshots</th>\n",
       "      <th>sort-orders</th>\n",
       "      <th>table-uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>1682526144303</td>\n",
       "      <td>s3a://go01-demo/warehouse/tablespace/external/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(1000, dob_hour, 4, hour)]</td>\n",
       "      <td>[([Row(field-id=1000, name='dob_hour', source-...</td>\n",
       "      <td>(pauldefusco,)</td>\n",
       "      <td>([(1, id, False, long), (2, state, False, stri...</td>\n",
       "      <td>[([Row(id=1, name='id', required=False, type='...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[([], 0)]</td>\n",
       "      <td>24ac86bb-a78d-49f8-9c8a-6288f0991a25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   current-schema-id  current-snapshot-id  default-sort-order-id  \\\n",
       "0                  0                   -1                      0   \n",
       "\n",
       "   default-spec-id  format-version  last-column-id  last-partition-id  \\\n",
       "0                0               1               4               1000   \n",
       "\n",
       "   last-updated-ms                                           location  \\\n",
       "0    1682526144303  s3a://go01-demo/warehouse/tablespace/external/...   \n",
       "\n",
       "  metadata-log               partition-spec  \\\n",
       "0           []  [(1000, dob_hour, 4, hour)]   \n",
       "\n",
       "                                     partition-specs      properties  \\\n",
       "0  [([Row(field-id=1000, name='dob_hour', source-...  (pauldefusco,)   \n",
       "\n",
       "                                              schema  \\\n",
       "0  ([(1, id, False, long), (2, state, False, stri...   \n",
       "\n",
       "                                             schemas snapshot-log snapshots  \\\n",
       "0  [([Row(id=1, name='id', required=False, type='...           []        []   \n",
       "\n",
       "  sort-orders                            table-uuid  \n",
       "0   [([], 0)]  24ac86bb-a78d-49f8-9c8a-6288f0991a25  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "spark.read.option(\"multiline\",\"true\").json(\"s3a://go01-demo/\" + metadata_file).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357d7e23-9be4-4b92-bbb0-cb69da6f1476",
   "metadata": {},
   "source": [
    "![alt text](../img/s3_metadata.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f6b96e-d878-4e2e-91a0-1ef785833479",
   "metadata": {},
   "source": [
    "#### Notice that no snapshots or other files have been created as data has not yet been inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "972dced2-83a3-4c4f-a63d-2936a54534d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+---------+-------------------+\n",
      "|made_current_at|snapshot_id|parent_id|is_current_ancestor|\n",
      "+---------------+-----------+---------+-------------------+\n",
      "+---------------+-----------+---------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM lakehouse_catalog.customers_table.history\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d726f825-38b0-4342-a0ea-0f932ce20355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+---------+---------+-------------+-------+\n",
      "|committed_at|snapshot_id|parent_id|operation|manifest_list|summary|\n",
      "+------------+-----------+---------+---------+-------------+-------+\n",
      "+------------+-----------+---------+---------+-------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM lakehouse_catalog.customers_table.snapshots;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68f5ad55-0adb-4ab3-8574-da44c3af6b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+-------+---------+------------+------------------+------------+------------+-----------------+----------------+------------+------------+------------+-------------+------------+-------------+\n",
      "|content|file_path|file_format|spec_id|partition|record_count|file_size_in_bytes|column_sizes|value_counts|null_value_counts|nan_value_counts|lower_bounds|upper_bounds|key_metadata|split_offsets|equality_ids|sort_order_id|\n",
      "+-------+---------+-----------+-------+---------+------------+------------------+------------+------------+-----------------+----------------+------------+------------+------------+-------------+------------+-------------+\n",
      "+-------+---------+-----------+-------+---------+------------+------------------+------------+------------+-----------------+----------------+------------+------------+------------+-------------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM lakehouse_catalog.customers_table.files;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "636820a4-528b-42f2-9153-2180206420de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+-----------------+-----------------+----------------------+-------------------------+------------------------+------------------------+---------------------------+--------------------------+-------------------+\n",
      "|content|path|length|partition_spec_id|added_snapshot_id|added_data_files_count|existing_data_files_count|deleted_data_files_count|added_delete_files_count|existing_delete_files_count|deleted_delete_files_count|partition_summaries|\n",
      "+-------+----+------+-----------------+-----------------+----------------------+-------------------------+------------------------+------------------------+---------------------------+--------------------------+-------------------+\n",
      "+-------+----+------+-----------------+-----------------+----------------------+-------------------------+------------------------+------------------------+---------------------------+--------------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM lakehouse_catalog.customers_table.manifests;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8544499-8ba1-4156-b641-89c10c281926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+-------+---------+------------+------------------+------------+------------+-----------------+----------------+------------+------------+------------+-------------+------------+-------------+\n",
      "|content|file_path|file_format|spec_id|partition|record_count|file_size_in_bytes|column_sizes|value_counts|null_value_counts|nan_value_counts|lower_bounds|upper_bounds|key_metadata|split_offsets|equality_ids|sort_order_id|\n",
      "+-------+---------+-----------+-------+---------+------------+------------------+------------+------------+-----------------+----------------+------------+------------+------------+-------------+------------+-------------+\n",
      "+-------+---------+-----------+-------+---------+------------+------------------+------------+------------+-----------------+----------------+------------+------------+------------+-------------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM lakehouse_catalog.customers_table.all_data_files;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "323639fc-1ed3-418d-ae0e-8c1674a30ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+-----------------+-----------------+----------------------+-------------------------+------------------------+------------------------+---------------------------+--------------------------+-------------------+---------------------+\n",
      "|content|path|length|partition_spec_id|added_snapshot_id|added_data_files_count|existing_data_files_count|deleted_data_files_count|added_delete_files_count|existing_delete_files_count|deleted_delete_files_count|partition_summaries|reference_snapshot_id|\n",
      "+-------+----+------+-----------------+-----------------+----------------------+-------------------------+------------------------+------------------------+---------------------------+--------------------------+-------------------+---------------------+\n",
      "+-------+----+------+-----------------+-----------------+----------------------+-------------------------+------------------------+------------------------+---------------------------+--------------------------+-------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM lakehouse_catalog.customers_table.all_manifests;\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24046132-45da-4f28-a60b-f0227b8fb7cc",
   "metadata": {},
   "source": [
    "### Table Insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "028f245c-e167-4418-9e96-fd098e0cb6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f2d7725-fe94-4a8c-82d0-319c1cefef8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"INSERT INTO lakehouse_catalog.customers_table VALUES (1, 'CA', 'USA', cast(date_format('2000-01-01 00:00:00', 'yyyy-MM-dd HH:mm:ss') as timestamp))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f0d668-9e68-4b1c-a881-5d1265f999c7",
   "metadata": {},
   "source": [
    "#### Validate that data has been added to the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da0242b8-93b9-4471-9aae-7a8f162a2320",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"select h.made_current_at,\\\n",
    "            s.operation,\\\n",
    "            h.snapshot_id,\\\n",
    "            h.is_current_ancestor,\\\n",
    "            s.summary['spark.app.id']\\\n",
    "        from lakehouse_catalog.customers_table.history h\\\n",
    "        join lakehouse_catalog.customers_table.snapshots s\\\n",
    "            on h.snapshot_id = s.snapshot_id\\\n",
    "            order by made_current_at;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76eaa58b-c77b-437a-979d-feaa4ac9b536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>made_current_at</th>\n",
       "      <th>operation</th>\n",
       "      <th>snapshot_id</th>\n",
       "      <th>is_current_ancestor</th>\n",
       "      <th>summary[spark.app.id]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-26 16:23:44.985</td>\n",
       "      <td>append</td>\n",
       "      <td>4069727943432154358</td>\n",
       "      <td>True</td>\n",
       "      <td>spark-application-1682526097424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          made_current_at operation          snapshot_id  is_current_ancestor  \\\n",
       "0 2023-04-26 16:23:44.985    append  4069727943432154358                 True   \n",
       "\n",
       "             summary[spark.app.id]  \n",
       "0  spark-application-1682526097424  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(QUERY).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557db97a-4cba-4ee7-b1f6-2b4f84d0c3db",
   "metadata": {},
   "source": [
    "![alt text](../img/s3_data_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316047e4-8ae2-4327-b5aa-ad39f9232415",
   "metadata": {},
   "source": [
    "![alt text](../img/s3_data_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a78f144-5617-4533-ab03-af69b857fd8c",
   "metadata": {},
   "source": [
    "#### Show all of the table’s data files and each file’s metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3728c7dc-ac75-4859-8790-501210b43381",
   "metadata": {},
   "source": [
    "#### Notice there are now two json files and two avro files. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f25b0-3aea-4b67-a5e5-bed3bf2b6a9d",
   "metadata": {},
   "source": [
    "The second json file reflects the new table version after the insert. Now, a new table read operation will point to this new file and ignore the previous one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f46899f-2ecd-4651-9dcf-7e6c4d912273",
   "metadata": {},
   "source": [
    "The avro file with the \"snap\" prefix is the manifest list. The other avro file created is the corresponding manifest file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8968ed18-4759-4cf0-9e18-98f537517a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata/00000-e19a6100-50ef-4556-a1ad-d13018d6286e.metadata.json\n",
      "\n",
      "warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata/00001-d9221d02-b558-473b-a7bf-347c90b86a9b.metadata.json\n",
      "\n",
      "warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata/66be1815-abfc-43c5-bf95-59720a6f3c79-m0.avro\n",
      "\n",
      "warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata/snap-4069727943432154358-1-66be1815-abfc-43c5-bf95-59720a6f3c79.avro\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket(\"go01-demo\")\n",
    "\n",
    "metadata_file_list = []\n",
    "\n",
    "for object_summary in my_bucket.objects.filter(Prefix=\"warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata\"):\n",
    "    print(object_summary.key +\"\\n\")\n",
    "    metadata_file_list.append(object_summary.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "022b7b8d-ec5e-4e7a-8f96-fa9929dd4c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata/00000-e19a6100-50ef-4556-a1ad-d13018d6286e.metadata.json',\n",
       " 'warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata/00001-d9221d02-b558-473b-a7bf-347c90b86a9b.metadata.json',\n",
       " 'warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata/66be1815-abfc-43c5-bf95-59720a6f3c79-m0.avro',\n",
       " 'warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata/snap-4069727943432154358-1-66be1815-abfc-43c5-bf95-59720a6f3c79.avro']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7cb383ed-5604-4d35-a525-bd7fb3501c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata/00000-e19a6100-50ef-4556-a1ad-d13018d6286e.metadata.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current-schema-id</th>\n",
       "      <th>current-snapshot-id</th>\n",
       "      <th>default-sort-order-id</th>\n",
       "      <th>default-spec-id</th>\n",
       "      <th>format-version</th>\n",
       "      <th>last-column-id</th>\n",
       "      <th>last-partition-id</th>\n",
       "      <th>last-updated-ms</th>\n",
       "      <th>location</th>\n",
       "      <th>metadata-log</th>\n",
       "      <th>partition-spec</th>\n",
       "      <th>partition-specs</th>\n",
       "      <th>properties</th>\n",
       "      <th>schema</th>\n",
       "      <th>schemas</th>\n",
       "      <th>snapshot-log</th>\n",
       "      <th>snapshots</th>\n",
       "      <th>sort-orders</th>\n",
       "      <th>table-uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>1682526144303</td>\n",
       "      <td>s3a://go01-demo/warehouse/tablespace/external/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(1000, dob_hour, 4, hour)]</td>\n",
       "      <td>[([Row(field-id=1000, name='dob_hour', source-...</td>\n",
       "      <td>(pauldefusco,)</td>\n",
       "      <td>([(1, id, False, long), (2, state, False, stri...</td>\n",
       "      <td>[([Row(id=1, name='id', required=False, type='...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[([], 0)]</td>\n",
       "      <td>24ac86bb-a78d-49f8-9c8a-6288f0991a25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   current-schema-id  current-snapshot-id  default-sort-order-id  \\\n",
       "0                  0                   -1                      0   \n",
       "\n",
       "   default-spec-id  format-version  last-column-id  last-partition-id  \\\n",
       "0                0               1               4               1000   \n",
       "\n",
       "   last-updated-ms                                           location  \\\n",
       "0    1682526144303  s3a://go01-demo/warehouse/tablespace/external/...   \n",
       "\n",
       "  metadata-log               partition-spec  \\\n",
       "0           []  [(1000, dob_hour, 4, hour)]   \n",
       "\n",
       "                                     partition-specs      properties  \\\n",
       "0  [([Row(field-id=1000, name='dob_hour', source-...  (pauldefusco,)   \n",
       "\n",
       "                                              schema  \\\n",
       "0  ([(1, id, False, long), (2, state, False, stri...   \n",
       "\n",
       "                                             schemas snapshot-log snapshots  \\\n",
       "0  [([Row(id=1, name='id', required=False, type='...           []        []   \n",
       "\n",
       "  sort-orders                            table-uuid  \n",
       "0   [([], 0)]  24ac86bb-a78d-49f8-9c8a-6288f0991a25  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Showing \" + metadata_file_list[0])\n",
    "spark.read.option(\"multiline\",\"true\").json(\"s3a://go01-demo/\" + metadata_file_list[0]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77983734-5f46-41bc-892e-9295ca6bb6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata/00001-d9221d02-b558-473b-a7bf-347c90b86a9b.metadata.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current-schema-id</th>\n",
       "      <th>current-snapshot-id</th>\n",
       "      <th>default-sort-order-id</th>\n",
       "      <th>default-spec-id</th>\n",
       "      <th>format-version</th>\n",
       "      <th>last-column-id</th>\n",
       "      <th>last-partition-id</th>\n",
       "      <th>last-updated-ms</th>\n",
       "      <th>location</th>\n",
       "      <th>metadata-log</th>\n",
       "      <th>partition-spec</th>\n",
       "      <th>partition-specs</th>\n",
       "      <th>properties</th>\n",
       "      <th>refs</th>\n",
       "      <th>schema</th>\n",
       "      <th>schemas</th>\n",
       "      <th>snapshot-log</th>\n",
       "      <th>snapshots</th>\n",
       "      <th>sort-orders</th>\n",
       "      <th>table-uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4069727943432154358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>1682526224985</td>\n",
       "      <td>s3a://go01-demo/warehouse/tablespace/external/...</td>\n",
       "      <td>[(s3a://go01-demo/warehouse/tablespace/externa...</td>\n",
       "      <td>[(1000, dob_hour, 4, hour)]</td>\n",
       "      <td>[([Row(field-id=1000, name='dob_hour', source-...</td>\n",
       "      <td>(pauldefusco,)</td>\n",
       "      <td>((4069727943432154358, branch),)</td>\n",
       "      <td>([(1, id, False, long), (2, state, False, stri...</td>\n",
       "      <td>[([Row(id=1, name='id', required=False, type='...</td>\n",
       "      <td>[(4069727943432154358, 1682526224985)]</td>\n",
       "      <td>[(s3a://go01-demo/warehouse/tablespace/externa...</td>\n",
       "      <td>[([], 0)]</td>\n",
       "      <td>24ac86bb-a78d-49f8-9c8a-6288f0991a25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   current-schema-id  current-snapshot-id  default-sort-order-id  \\\n",
       "0                  0  4069727943432154358                      0   \n",
       "\n",
       "   default-spec-id  format-version  last-column-id  last-partition-id  \\\n",
       "0                0               1               4               1000   \n",
       "\n",
       "   last-updated-ms                                           location  \\\n",
       "0    1682526224985  s3a://go01-demo/warehouse/tablespace/external/...   \n",
       "\n",
       "                                        metadata-log  \\\n",
       "0  [(s3a://go01-demo/warehouse/tablespace/externa...   \n",
       "\n",
       "                partition-spec  \\\n",
       "0  [(1000, dob_hour, 4, hour)]   \n",
       "\n",
       "                                     partition-specs      properties  \\\n",
       "0  [([Row(field-id=1000, name='dob_hour', source-...  (pauldefusco,)   \n",
       "\n",
       "                               refs  \\\n",
       "0  ((4069727943432154358, branch),)   \n",
       "\n",
       "                                              schema  \\\n",
       "0  ([(1, id, False, long), (2, state, False, stri...   \n",
       "\n",
       "                                             schemas  \\\n",
       "0  [([Row(id=1, name='id', required=False, type='...   \n",
       "\n",
       "                             snapshot-log  \\\n",
       "0  [(4069727943432154358, 1682526224985)]   \n",
       "\n",
       "                                           snapshots sort-orders  \\\n",
       "0  [(s3a://go01-demo/warehouse/tablespace/externa...   [([], 0)]   \n",
       "\n",
       "                             table-uuid  \n",
       "0  24ac86bb-a78d-49f8-9c8a-6288f0991a25  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Showing \" + metadata_file_list[1])\n",
    "spark.read.option(\"multiline\",\"true\").json(\"s3a://go01-demo/\" + metadata_file_list[1]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f09c777a-d717-4c8c-a098-eca4972e0f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata/66be1815-abfc-43c5-bf95-59720a6f3c79-m0.avro\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>snapshot_id</th>\n",
       "      <th>data_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4069727943432154358</td>\n",
       "      <td>(s3a://go01-demo/warehouse/tablespace/external...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   status          snapshot_id  \\\n",
       "0       1  4069727943432154358   \n",
       "\n",
       "                                           data_file  \n",
       "0  (s3a://go01-demo/warehouse/tablespace/external...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Showing \" + metadata_file_list[2])\n",
    "spark.read.format(\"avro\").load(\"s3a://go01-demo/\" + metadata_file_list[2]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1eb30215-5e39-429d-b0a7-6284c2b25a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata/snap-4069727943432154358-1-66be1815-abfc-43c5-bf95-59720a6f3c79.avro\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manifest_path</th>\n",
       "      <th>manifest_length</th>\n",
       "      <th>partition_spec_id</th>\n",
       "      <th>added_snapshot_id</th>\n",
       "      <th>added_data_files_count</th>\n",
       "      <th>existing_data_files_count</th>\n",
       "      <th>deleted_data_files_count</th>\n",
       "      <th>partitions</th>\n",
       "      <th>added_rows_count</th>\n",
       "      <th>existing_rows_count</th>\n",
       "      <th>deleted_rows_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s3a://go01-demo/warehouse/tablespace/external/...</td>\n",
       "      <td>6189</td>\n",
       "      <td>0</td>\n",
       "      <td>4069727943432154358</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(False, False, [56, 3, 4, 0], [56, 3, 4, 0])]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       manifest_path  manifest_length  \\\n",
       "0  s3a://go01-demo/warehouse/tablespace/external/...             6189   \n",
       "\n",
       "   partition_spec_id    added_snapshot_id  added_data_files_count  \\\n",
       "0                  0  4069727943432154358                       1   \n",
       "\n",
       "   existing_data_files_count  deleted_data_files_count  \\\n",
       "0                          0                         0   \n",
       "\n",
       "                                       partitions  added_rows_count  \\\n",
       "0  [(False, False, [56, 3, 4, 0], [56, 3, 4, 0])]                 1   \n",
       "\n",
       "   existing_rows_count  deleted_rows_count  \n",
       "0                    0                   0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Showing \" + metadata_file_list[3])\n",
    "spark.read.format(\"avro\").load(\"s3a://go01-demo/\" + metadata_file_list[3]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "916c5ebb-e869-4ad0-998e-86e89114af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "file3 = spark.read.format(\"avro\").load(\"s3a://go01-demo/\" + metadata_file_list[3]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "824d6433-d0f3-47e1-8c00-b64d1ed34c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3a://go01-demo/warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata/66be1815-abfc-43c5-bf95-59720a6f3c79-m0.avro'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file3['manifest_path'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f023c1ca-48c8-4d4d-b329-4825d473bf4b",
   "metadata": {},
   "source": [
    "### Table Update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bef6e0-6ea1-4f75-aeac-fd84b0b7f2f7",
   "metadata": {},
   "source": [
    "Create a staging table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8287cfa-9f8e-40fb-a880-a2dabcdbd2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS lakehouse_catalog.staging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a742c99-a211-4fa6-bdd5-e63f8079f9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE TABLE IF NOT EXISTS lakehouse_catalog.staging\\\n",
    "            (id BIGINT, state STRING, country STRING, dob TIMESTAMP)\\\n",
    "            USING iceberg\\\n",
    "            PARTITIONED BY ( hours(dob))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4dc4207-34e0-4bb3-a147-dfcd4e601990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"INSERT INTO lakehouse_catalog.staging\\\n",
    "            VALUES (1, 'ID', 'USA', cast(date_format('2000-01-01 00:00:00', 'yyyy-MM-dd HH:mm:ss') as timestamp)),\\\n",
    "            (2, 'CA', 'USA', cast(date_format('2000-01-03 00:10:00', 'yyyy-MM-dd HH:mm:ss') as timestamp)),\\\n",
    "            (3, 'AZ', 'USA', cast(date_format('2000-01-04 00:01:00', 'yyyy-MM-dd HH:mm:ss') as timestamp)),\\\n",
    "            (4, 'NV', 'USA', cast(date_format('2000-01-02 00:02:00', 'yyyy-MM-dd HH:mm:ss') as timestamp)),\\\n",
    "            (5, 'OR', 'USA', cast(date_format('2000-01-03 00:03:00', 'yyyy-MM-dd HH:mm:ss') as timestamp)),\\\n",
    "            (10, 'WA', 'USA', cast(date_format('2000-01-04 00:03:00', 'yyyy-MM-dd HH:mm:ss') as timestamp)),\\\n",
    "            (3, 'UT', 'USA', cast(date_format('2000-01-01 00:04:00', 'yyyy-MM-dd HH:mm:ss') as timestamp)),\\\n",
    "            (11, 'CO', 'USA', cast(date_format('2000-01-01 00:03:00', 'yyyy-MM-dd HH:mm:ss') as timestamp)),\\\n",
    "            (6, 'CO', 'USA', cast(date_format('2000-01-01 00:03:00', 'yyyy-MM-dd HH:mm:ss') as timestamp))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c3720c-3011-4a15-924f-de39a525501d",
   "metadata": {},
   "source": [
    "Merge Into Customers Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b62e634-935e-4219-b240-fdb8411b2984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"MERGE INTO lakehouse_catalog.customers_table\\\n",
    "            USING (SELECT * FROM lakehouse_catalog.staging) a\\\n",
    "            ON customers_table.id = a.id\\\n",
    "            WHEN MATCHED THEN UPDATE SET customers_table.state = a.state\\\n",
    "            WHEN NOT MATCHED THEN INSERT *\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c94305e6-c808-4d67-8903-864a4d80b5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>committed_at</th>\n",
       "      <th>snapshot_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>operation</th>\n",
       "      <th>manifest_list</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-26 16:23:44.985</td>\n",
       "      <td>4069727943432154358</td>\n",
       "      <td>NaN</td>\n",
       "      <td>append</td>\n",
       "      <td>s3a://go01-demo/warehouse/tablespace/external/...</td>\n",
       "      <td>{'spark.app.id': 'spark-application-1682526097...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-26 16:44:55.770</td>\n",
       "      <td>314145575071817500</td>\n",
       "      <td>4.069728e+18</td>\n",
       "      <td>overwrite</td>\n",
       "      <td>s3a://go01-demo/warehouse/tablespace/external/...</td>\n",
       "      <td>{'added-data-files': '4', 'total-equality-dele...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             committed_at          snapshot_id     parent_id  operation  \\\n",
       "0 2023-04-26 16:23:44.985  4069727943432154358           NaN     append   \n",
       "1 2023-04-26 16:44:55.770   314145575071817500  4.069728e+18  overwrite   \n",
       "\n",
       "                                       manifest_list  \\\n",
       "0  s3a://go01-demo/warehouse/tablespace/external/...   \n",
       "1  s3a://go01-demo/warehouse/tablespace/external/...   \n",
       "\n",
       "                                             summary  \n",
       "0  {'spark.app.id': 'spark-application-1682526097...  \n",
       "1  {'added-data-files': '4', 'total-equality-dele...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM lakehouse_catalog.customers_table.snapshots;\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2d2d2db3-6d38-428e-bc8d-51286ff2e11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>path</th>\n",
       "      <th>length</th>\n",
       "      <th>partition_spec_id</th>\n",
       "      <th>added_snapshot_id</th>\n",
       "      <th>added_data_files_count</th>\n",
       "      <th>existing_data_files_count</th>\n",
       "      <th>deleted_data_files_count</th>\n",
       "      <th>added_delete_files_count</th>\n",
       "      <th>existing_delete_files_count</th>\n",
       "      <th>deleted_delete_files_count</th>\n",
       "      <th>partition_summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>s3a://go01-demo/warehouse/tablespace/external/...</td>\n",
       "      <td>6365</td>\n",
       "      <td>0</td>\n",
       "      <td>314145575071817500</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(False, False, 2000-01-01-00, 2000-01-04-00)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>s3a://go01-demo/warehouse/tablespace/external/...</td>\n",
       "      <td>6191</td>\n",
       "      <td>0</td>\n",
       "      <td>314145575071817500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(False, False, 2000-01-01-00, 2000-01-01-00)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   content                                               path  length  \\\n",
       "0        0  s3a://go01-demo/warehouse/tablespace/external/...    6365   \n",
       "1        0  s3a://go01-demo/warehouse/tablespace/external/...    6191   \n",
       "\n",
       "   partition_spec_id   added_snapshot_id  added_data_files_count  \\\n",
       "0                  0  314145575071817500                       4   \n",
       "1                  0  314145575071817500                       0   \n",
       "\n",
       "   existing_data_files_count  deleted_data_files_count  \\\n",
       "0                          0                         0   \n",
       "1                          0                         1   \n",
       "\n",
       "   added_delete_files_count  existing_delete_files_count  \\\n",
       "0                         0                            0   \n",
       "1                         0                            0   \n",
       "\n",
       "   deleted_delete_files_count                             partition_summaries  \n",
       "0                           0  [(False, False, 2000-01-01-00, 2000-01-04-00)]  \n",
       "1                           0  [(False, False, 2000-01-01-00, 2000-01-01-00)]  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM lakehouse_catalog.customers_table.manifests;\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db59e20d-b4fa-455c-8a34-b5538d06b2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>file_path</th>\n",
       "      <th>file_format</th>\n",
       "      <th>spec_id</th>\n",
       "      <th>partition</th>\n",
       "      <th>record_count</th>\n",
       "      <th>file_size_in_bytes</th>\n",
       "      <th>column_sizes</th>\n",
       "      <th>value_counts</th>\n",
       "      <th>null_value_counts</th>\n",
       "      <th>nan_value_counts</th>\n",
       "      <th>lower_bounds</th>\n",
       "      <th>upper_bounds</th>\n",
       "      <th>key_metadata</th>\n",
       "      <th>split_offsets</th>\n",
       "      <th>equality_ids</th>\n",
       "      <th>sort_order_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>s3a://go01-demo/warehouse/tablespace/external/...</td>\n",
       "      <td>PARQUET</td>\n",
       "      <td>0</td>\n",
       "      <td>(262968,)</td>\n",
       "      <td>4</td>\n",
       "      <td>1277</td>\n",
       "      <td>{1: 57, 2: 74, 3: 61, 4: 80}</td>\n",
       "      <td>{1: 4, 2: 4, 3: 4, 4: 4}</td>\n",
       "      <td>{1: 0, 2: 0, 3: 0, 4: 0}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{1: [1, 0, 0, 0, 0, 0, 0, 0], 2: [67, 79], 3: ...</td>\n",
       "      <td>{1: [11, 0, 0, 0, 0, 0, 0, 0], 2: [85, 84], 3:...</td>\n",
       "      <td>None</td>\n",
       "      <td>[4]</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>s3a://go01-demo/warehouse/tablespace/external/...</td>\n",
       "      <td>PARQUET</td>\n",
       "      <td>0</td>\n",
       "      <td>(262992,)</td>\n",
       "      <td>1</td>\n",
       "      <td>1130</td>\n",
       "      <td>{1: 39, 2: 37, 3: 38, 4: 39}</td>\n",
       "      <td>{1: 1, 2: 1, 3: 1, 4: 1}</td>\n",
       "      <td>{1: 0, 2: 0, 3: 0, 4: 0}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{1: [4, 0, 0, 0, 0, 0, 0, 0], 2: [78, 86], 3: ...</td>\n",
       "      <td>{1: [4, 0, 0, 0, 0, 0, 0, 0], 2: [78, 86], 3: ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[4]</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>s3a://go01-demo/warehouse/tablespace/external/...</td>\n",
       "      <td>PARQUET</td>\n",
       "      <td>0</td>\n",
       "      <td>(263016,)</td>\n",
       "      <td>2</td>\n",
       "      <td>1176</td>\n",
       "      <td>{1: 46, 2: 43, 3: 61, 4: 47}</td>\n",
       "      <td>{1: 2, 2: 2, 3: 2, 4: 2}</td>\n",
       "      <td>{1: 0, 2: 0, 3: 0, 4: 0}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{1: [2, 0, 0, 0, 0, 0, 0, 0], 2: [67, 65], 3: ...</td>\n",
       "      <td>{1: [5, 0, 0, 0, 0, 0, 0, 0], 2: [79, 82], 3: ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[4]</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>s3a://go01-demo/warehouse/tablespace/external/...</td>\n",
       "      <td>PARQUET</td>\n",
       "      <td>0</td>\n",
       "      <td>(263040,)</td>\n",
       "      <td>2</td>\n",
       "      <td>1177</td>\n",
       "      <td>{1: 47, 2: 43, 3: 61, 4: 47}</td>\n",
       "      <td>{1: 2, 2: 2, 3: 2, 4: 2}</td>\n",
       "      <td>{1: 0, 2: 0, 3: 0, 4: 0}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{1: [3, 0, 0, 0, 0, 0, 0, 0], 2: [65, 90], 3: ...</td>\n",
       "      <td>{1: [10, 0, 0, 0, 0, 0, 0, 0], 2: [87, 65], 3:...</td>\n",
       "      <td>None</td>\n",
       "      <td>[4]</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>s3a://go01-demo/warehouse/tablespace/external/...</td>\n",
       "      <td>PARQUET</td>\n",
       "      <td>0</td>\n",
       "      <td>(262968,)</td>\n",
       "      <td>1</td>\n",
       "      <td>1106</td>\n",
       "      <td>{1: 33, 2: 31, 3: 32, 4: 39}</td>\n",
       "      <td>{1: 1, 2: 1, 3: 1, 4: 1}</td>\n",
       "      <td>{1: 0, 2: 0, 3: 0, 4: 0}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{1: [1, 0, 0, 0, 0, 0, 0, 0], 2: [67, 65], 3: ...</td>\n",
       "      <td>{1: [1, 0, 0, 0, 0, 0, 0, 0], 2: [67, 65], 3: ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[4]</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   content                                          file_path file_format  \\\n",
       "0        0  s3a://go01-demo/warehouse/tablespace/external/...     PARQUET   \n",
       "1        0  s3a://go01-demo/warehouse/tablespace/external/...     PARQUET   \n",
       "2        0  s3a://go01-demo/warehouse/tablespace/external/...     PARQUET   \n",
       "3        0  s3a://go01-demo/warehouse/tablespace/external/...     PARQUET   \n",
       "4        0  s3a://go01-demo/warehouse/tablespace/external/...     PARQUET   \n",
       "\n",
       "   spec_id  partition  record_count  file_size_in_bytes  \\\n",
       "0        0  (262968,)             4                1277   \n",
       "1        0  (262992,)             1                1130   \n",
       "2        0  (263016,)             2                1176   \n",
       "3        0  (263040,)             2                1177   \n",
       "4        0  (262968,)             1                1106   \n",
       "\n",
       "                   column_sizes              value_counts  \\\n",
       "0  {1: 57, 2: 74, 3: 61, 4: 80}  {1: 4, 2: 4, 3: 4, 4: 4}   \n",
       "1  {1: 39, 2: 37, 3: 38, 4: 39}  {1: 1, 2: 1, 3: 1, 4: 1}   \n",
       "2  {1: 46, 2: 43, 3: 61, 4: 47}  {1: 2, 2: 2, 3: 2, 4: 2}   \n",
       "3  {1: 47, 2: 43, 3: 61, 4: 47}  {1: 2, 2: 2, 3: 2, 4: 2}   \n",
       "4  {1: 33, 2: 31, 3: 32, 4: 39}  {1: 1, 2: 1, 3: 1, 4: 1}   \n",
       "\n",
       "          null_value_counts nan_value_counts  \\\n",
       "0  {1: 0, 2: 0, 3: 0, 4: 0}               {}   \n",
       "1  {1: 0, 2: 0, 3: 0, 4: 0}               {}   \n",
       "2  {1: 0, 2: 0, 3: 0, 4: 0}               {}   \n",
       "3  {1: 0, 2: 0, 3: 0, 4: 0}               {}   \n",
       "4  {1: 0, 2: 0, 3: 0, 4: 0}               {}   \n",
       "\n",
       "                                        lower_bounds  \\\n",
       "0  {1: [1, 0, 0, 0, 0, 0, 0, 0], 2: [67, 79], 3: ...   \n",
       "1  {1: [4, 0, 0, 0, 0, 0, 0, 0], 2: [78, 86], 3: ...   \n",
       "2  {1: [2, 0, 0, 0, 0, 0, 0, 0], 2: [67, 65], 3: ...   \n",
       "3  {1: [3, 0, 0, 0, 0, 0, 0, 0], 2: [65, 90], 3: ...   \n",
       "4  {1: [1, 0, 0, 0, 0, 0, 0, 0], 2: [67, 65], 3: ...   \n",
       "\n",
       "                                        upper_bounds key_metadata  \\\n",
       "0  {1: [11, 0, 0, 0, 0, 0, 0, 0], 2: [85, 84], 3:...         None   \n",
       "1  {1: [4, 0, 0, 0, 0, 0, 0, 0], 2: [78, 86], 3: ...         None   \n",
       "2  {1: [5, 0, 0, 0, 0, 0, 0, 0], 2: [79, 82], 3: ...         None   \n",
       "3  {1: [10, 0, 0, 0, 0, 0, 0, 0], 2: [87, 65], 3:...         None   \n",
       "4  {1: [1, 0, 0, 0, 0, 0, 0, 0], 2: [67, 65], 3: ...         None   \n",
       "\n",
       "  split_offsets equality_ids  sort_order_id  \n",
       "0           [4]         None              0  \n",
       "1           [4]         None              0  \n",
       "2           [4]         None              0  \n",
       "3           [4]         None              0  \n",
       "4           [4]         None              0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM lakehouse_catalog.customers_table.all_data_files;\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9486357-7744-4068-998c-7bb4a9edf5da",
   "metadata": {},
   "source": [
    "#### There is a new metadata file (json) prefixed by 0002"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9308c678-d334-4a0b-8b14-94c0164c9be5",
   "metadata": {},
   "source": [
    "#### There is a new manifest list file (avro) prefixed by \"snap\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1685d9f-422a-44dc-a969-e4e3d5b0718c",
   "metadata": {},
   "source": [
    "#### There is a new manifest file (avro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "91fd6085-7047-437b-9b5d-08a5a43dc13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata/00000-2e11b1f4-cdb2-4cfb-a3e7-1d572c5186ef.metadata.json\n",
      "\n",
      "warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata/00001-aa607d9c-52c9-4208-bd50-8a29103a0269.metadata.json\n",
      "\n",
      "warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata/00002-8a99b449-0dd8-4dd1-bfb0-53c510c12334.metadata.json\n",
      "\n",
      "warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata/dde17409-0dcd-42f0-a2d5-8c8838b49f7b-m0.avro\n",
      "\n",
      "warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata/fdf81d84-1f96-4bda-a83c-a98a3a35805d-m0.avro\n",
      "\n",
      "warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata/fdf81d84-1f96-4bda-a83c-a98a3a35805d-m1.avro\n",
      "\n",
      "warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata/snap-2397883159392124377-1-fdf81d84-1f96-4bda-a83c-a98a3a35805d.avro\n",
      "\n",
      "warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata/snap-8989698068481370389-1-dde17409-0dcd-42f0-a2d5-8c8838b49f7b.avro\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket(\"go01-demo\")\n",
    "\n",
    "for object_summary in my_bucket.objects.filter(Prefix=\"warehouse/tablespace/external/hive/lakehouse_catalog.db/customers_table/metadata\"):\n",
    "    print(object_summary.key +\"\\n\")\n",
    "    metadata_file = object_summary.key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62108a25-7170-4760-88a9-bbe2a80581b3",
   "metadata": {},
   "source": [
    "### Time Travel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c566c5c6-8b5d-4aba-9c20-409233c4827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshots_df = spark.sql(\"SELECT * FROM lakehouse_catalog.customers_table.snapshots;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0852473c-3639-43c1-a446-8920be731f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "first_snapshot = snapshots_df.select(\"snapshot_id\").head(1)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb18fe8c-fb4f-4669-a52e-fbe024979e4b",
   "metadata": {},
   "source": [
    "#### Validate that the output dataframe only includes one row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7c0cd767-66f2-4393-8a2f-0d1d89e6a973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>dob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>USA</td>\n",
       "      <td>2000-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id state country        dob\n",
       "0   1    CA     USA 2000-01-01"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read\\\n",
    "    .option(\"snapshot-id\", first_snapshot)\\\n",
    "    .format(\"iceberg\")\\\n",
    "    .load(\"lakehouse_catalog.customers_table\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0086fbd-2b28-4df6-baf9-17768c5a7b9b",
   "metadata": {},
   "source": [
    "### Drop the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "abab5842-1722-470e-8066-c58e7659192e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS lakehouse_catalog.staging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074792f9-ef49-4e6c-beaf-4883e3b87265",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
